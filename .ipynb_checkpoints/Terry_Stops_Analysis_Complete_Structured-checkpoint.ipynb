{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Terry Stops Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Business Understanding**\n",
    "The goal of this project is to analyze Terry Stops data and predict whether an arrest will occur based on various features. Terry Stops are brief detentions made by law enforcement officers when there is reasonable suspicion of criminal activity. Understanding which factors contribute to arrests can help ensure fair policing strategies and improve transparency in law enforcement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Understanding**\n",
    "This section explores the dataset structure, including missing values, categorical variables, and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Terry_Stops.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display dataset structure\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3684405230.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Dataset Shape:\", df.shape) print(\"\\nColumn Information:\") print(df.info())\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", df.shape) print(\"\\nColumn Information:\") print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display first few rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check unique values in categorical variables\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "display(df[categorical_columns].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "display(df.describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Exploratory Data Analysis (EDA)**\n",
    "EDA helps us understand patterns, trends, and relationships within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the distribution of the target variable\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='Arrest Flag', palette='coolwarm')\n",
    "plt.title(\"Distribution of Arrests\")\n",
    "plt.xlabel(\"Arrest Made\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Data Preprocessing & Feature Engineering**\n",
    "This step ensures the dataset is clean and structured for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['Reported Year', 'Reported Month', 'Reported Day', 'Reported Weekday', 'Reported Hour', 'Officer YOB']\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Modeling**\n",
    "This section covers training multiple models, including Logistic Regression, Random Forest, and Support Vector Machines (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Class Imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(df.drop(columns=['Arrest Flag']), df['Arrest Flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipelines for models\n",
    "logistic_pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', LogisticRegression(max_iter=1000, random_state=42))])\n",
    "rf_pipeline = Pipeline([('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))])\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models\n",
    "models = {'Logistic Regression': logistic_pipeline, 'Random Forest': rf_pipeline, 'Gradient Boosting': gb_model, 'SVM': svm_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(model.score(X_test, y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Evaluation**\n",
    "We evaluate the models using classification metrics and ROC Curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Best Model (Random Forest)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, rf_pipeline.fit(X_train, y_train).predict(X_test)), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve\n",
    "plt.figure(figsize=(6,4))\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc(fpr, tpr):.3f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Conclusion & Recommendations**\n",
    "### Key Takeaways:\n",
    "- **Random Forest emerged as the best-performing model**, making it suitable for law enforcement applications.\n",
    "- **Logistic Regression performed well as a baseline model**, but lacked flexibility for complex data relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations:\n",
    "1. **Enhance Data Collection:** Gather additional features such as **officer experience, location history, and previous stops**.\n",
    "2. **Address Potential Biases:** Investigate potential **racial, gender, or location-based biases**.\n",
    "3. **Deploy Model for Real-World Applications:** Implement a **real-time prediction system** to assist law enforcement.\n",
    "4. **Further Model Improvements:** Optimize models with **advanced hyperparameter tuning** and **ensemble techniques**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
